{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cpu\nTrain on 160 samples, validate on 40 samples, 1 steps per epoch\nEpoch 1/10\n0s - loss:  14.3369 - mse:  14.3369 - val_mse:  13.2144\nEpoch 2/10\n0s - loss:  13.9993 - mse:  13.9993 - val_mse:  12.9205\nEpoch 3/10\n0s - loss:  13.6893 - mse:  13.6893 - val_mse:  12.6459\nEpoch 4/10\n0s - loss:  13.3997 - mse:  13.3997 - val_mse:  12.4208\nEpoch 5/10\n0s - loss:  13.1610 - mse:  13.1610 - val_mse:  12.2067\nEpoch 6/10\n0s - loss:  12.9335 - mse:  12.9335 - val_mse:  11.9843\nEpoch 7/10\n0s - loss:  12.6973 - mse:  12.6973 - val_mse:  11.7535\nEpoch 8/10\n0s - loss:  12.4522 - mse:  12.4522 - val_mse:  11.5141\nEpoch 9/10\n0s - loss:  12.1982 - mse:  12.1982 - val_mse:  11.2660\nEpoch 10/10\n0s - loss:  11.9348 - mse:  11.9348 - val_mse:  11.0091\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from deepctr_torch.inputs import SparseFeat, VarLenSparseFeat, get_feature_names\n",
    "from deepctr_torch.models import DeepFM\n",
    "\n",
    "\n",
    "def split(x):\n",
    "    key_ans = x.split('|')\n",
    "    for key in key_ans:\n",
    "        if key not in key2index:\n",
    "            # Notice : input value 0 is a special \"padding\",so we do not use 0 to encode valid feature for sequence input\n",
    "            key2index[key] = len(key2index) + 1\n",
    "    return list(map(lambda x: key2index[x], key_ans))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = pd.read_csv(\"./movielens_sample.txt\")\n",
    "#     sparse_features = [\"movie_id\", \"user_id\",\n",
    "#                        \"gender\", \"age\", \"occupation\", \"zip\", ]\n",
    "    sparse_features = [\"movie_id\", \"gender\", \"age\"]\n",
    "    target = ['rating']\n",
    "\n",
    "    # 1.Label Encoding for sparse features,and process sequence features\n",
    "    for feat in sparse_features:\n",
    "        lbe = LabelEncoder()\n",
    "        data[feat] = lbe.fit_transform(data[feat])\n",
    "    # preprocess the sequence feature\n",
    "\n",
    "    key2index = {}\n",
    "    genres_list = list(map(split, data['genres'].values))\n",
    "    genres_length = np.array(list(map(len, genres_list)))\n",
    "    max_len = max(genres_length)\n",
    "    # Notice : padding=`post`\n",
    "    genres_list = pad_sequences(genres_list, maxlen=max_len, padding='post', )\n",
    "\n",
    "    # 2.count #unique features for each sparse field and generate feature config for sequence feature\n",
    "\n",
    "    fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique(), embedding_dim=4)\n",
    "                              for feat in sparse_features]\n",
    "\n",
    "    varlen_feature_columns = [VarLenSparseFeat(SparseFeat('genres', vocabulary_size=len(\n",
    "        key2index) + 1, embedding_dim=4), maxlen=max_len, combiner='mean',)]  \n",
    "    # Notice : value 0 is for padding for sequence input feature\n",
    "\n",
    "    linear_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "    dnn_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "\n",
    "    feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "    # 3.generate input data for model\n",
    "    model_input = {name: data[name] for name in sparse_features}  #\n",
    "    model_input[\"genres\"] = genres_list\n",
    "\n",
    "    # 4.Define Model,compile and train\n",
    "\n",
    "    device = 'cpu'\n",
    "#     use_cuda = True\n",
    "    use_cuda = False\n",
    "    if use_cuda and torch.cuda.is_available():\n",
    "        print('cuda ready...')\n",
    "        device = 'cuda:0'\n",
    "\n",
    "    model = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "#     model = DeepFM(linear_feature_columns, dnn_feature_columns, task='multiclass', device=device)\n",
    "\n",
    "    model.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "#     model.compile(\"adam\", \"binary_crossentropy\", metrics=['acc'], )\n",
    "\n",
    "    history = model.fit(model_input, data[target].values,\n",
    "                        batch_size=256, epochs=10, verbose=2, validation_split=0.2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "test MSE 12.218\n"
    }
   ],
   "source": [
    "# test_model_input = {}\n",
    "# for name in sparse_features:\n",
    "#      test_model_input[name] = model_input[name][0:5]\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "test_model_input = {name: data[name][0:5] for name in sparse_features}\n",
    "test_model_input[\"genres\"] = genres_list[0:5]\n",
    "\n",
    "pred_ans = model.predict(test_model_input, batch_size=256)\n",
    "\n",
    "true_ans = data[target][0:5].values\n",
    "print(\"test MSE\", round(mean_squared_error(true_ans, pred_ans), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, values in  model_input.items():\n",
    "#     print(key, values)\n",
    "    print(key)\n",
    "    print('-----')\n",
    "    print(values[0])\n",
    "    print(type(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data[target].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data[target].values)\n",
    "data[target].values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 2 2 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 1 1 2 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 2 1 1 1 1 1 1 1 1 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1]\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186]\n"
     ]
    }
   ],
   "source": [
    "unique_items, counts = np.unique(data[target].values, return_counts=True)\n",
    "print(counts)\n",
    "print(unique_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type((model_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}