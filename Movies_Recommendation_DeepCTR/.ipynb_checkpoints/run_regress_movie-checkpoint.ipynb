{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda ready...\n",
      "cuda:0\n",
      "Train on 64000 samples, validate on 16000 samples, 250 steps per epoch\n",
      "Epoch 1/1\n",
      "3s - loss:  1.5526 - mse:  1.5526 - val_mse:  1.0457\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d9f1d7c61141>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m     history = model.fit(train_model_input, train[target].values,\n\u001b[1;32m     55\u001b[0m                         batch_size=256, epochs=1, verbose=2, validation_split=0.2, )\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mpred_ans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_model_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     print(\"test MSE\", round(mean_squared_error(\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/deepctr_torch/models/basemodel.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, use_double)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         tensor_data = Data.TensorDataset(\n\u001b[0;32m--> 292\u001b[0;31m             torch.from_numpy(np.concatenate(x, axis=-1)))\n\u001b[0m\u001b[1;32m    293\u001b[0m         test_loader = DataLoader(\n\u001b[1;32m    294\u001b[0m             dataset=tensor_data, shuffle=False, batch_size=batch_size)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from deepctr_torch.inputs import SparseFeat, get_feature_names\n",
    "from deepctr_torch.models import DeepFM, FiBiNET, xDeepFM, ONN, AutoInt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "#     data = pd.read_csv(\"./movielens_sample.txt\")\n",
    "    data = pd.read_csv(\"./data.csv\")\n",
    "    mytest = pd.read_csv(\"./test.csv\") ###\n",
    "#     sparse_features = [\"movie_id\", \"user_id\",\n",
    "#                        \"gender\", \"age\", \"occupation\", \"zip\"]\n",
    "    sparse_features = [\"movie_id\", \"gender\", \"age\"]\n",
    "    target = ['rating']\n",
    "#     target = ['movie_id']\n",
    "\n",
    "    # 1.Label Encoding for sparse features,and do simple Transformation for dense features\n",
    "    for feat in sparse_features:\n",
    "        lbe = LabelEncoder()\n",
    "        data[feat] = lbe.fit_transform(data[feat])\n",
    "        mytest[feat] = lbe.fit_transform(test[feat])\n",
    "    # 2.count #unique features for each sparse field\n",
    "    fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique())\n",
    "                              for feat in sparse_features]\n",
    "    mytest_fixlen_feature_columns = [SparseFeat(feat, mytest[feat].nunique())\n",
    "                              for feat in sparse_features] ### 看要不要用data[feat].nunique!!!!!!!!!\n",
    "    \n",
    "    # 他自己的資料型態\n",
    "    # SparseFeat(name='movie_id', vocabulary_size=187, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='movie_id', group_name='default_group')\n",
    "    linear_feature_columns = fixlen_feature_columns  \n",
    "    dnn_feature_columns = fixlen_feature_columns\n",
    "    feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)  # movie_id, user_id, gender, age, occupation, zip.\n",
    "    mytest_feature_names = get_feature_names(mytest_fixlen_feature_columns+mytest_fixlen_feature_columns)\n",
    "    \n",
    "    # 3.generate input data for model !!!!!!!!!!!!!!!!!\n",
    "    train, test = train_test_split(data, test_size=0.2)\n",
    "    train_model_input = {name: train[name] for name in feature_names}\n",
    "    test_model_input = {name: test[name] for name in feature_names}  # dict of movie_id, user_id, gender, age, occupation, zip\n",
    "    mytest_model_input = {name: mytest[name] for name in feature_names}  # dict of movie_id, user_id, gender, age, occupation, zip\n",
    "    \n",
    "    # 4.Define Model,train,predict and evaluate\n",
    "    device = 'cpu'\n",
    "    use_cuda = True\n",
    "    if use_cuda and torch.cuda.is_available():\n",
    "        print('cuda ready...')\n",
    "        device = 'cuda:0'\n",
    "\n",
    "    # model = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    # model = FiBiNET(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    model = xDeepFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "    model.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "\n",
    "    history = model.fit(train_model_input, train[target].values,\n",
    "                        batch_size=256, epochs=1, verbose=2, validation_split=0.2, )\n",
    "#     pred_ans = model.predict(test_model_input, batch_size=256)\n",
    "    pred_ans = model.predict(mytest_model_input, batch_size=256)\n",
    "    print(\"test MSE\", round(mean_squared_error(\n",
    "        test[target].values, pred_ans), 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.37085\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for pred, ans in zip(pred_ans, test[target].values):\n",
    "    if abs((pred) - ans) <= 0.5:\n",
    "        correct += 1\n",
    "    # print(f\"pred_ans: {np.around(pred)}, ans: {ans}\")\n",
    "print(f'acc:{correct / len(pred_ans)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:0.3745\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for pred, ans in zip(pred_ans, test[target].values):\n",
    "    if abs(np.around(pred) - ans) == 0:\n",
    "        correct += 1\n",
    "    # print(f\"pred_ans: {np.around(pred)}, ans: {ans}\")\n",
    "print(f'acc:{correct / len(pred_ans)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, values in  test_model_input.items():\n",
    "#     print(key, values)\n",
    "    print(key)\n",
    "    print('-----')\n",
    "    print(type(values))\n",
    "#     print(values.head())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_feature_names(linear_feature_columns )\n",
    "get_feature_names(dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_model_input['zip'])\n",
    "type(test_model_input['zip'])\n",
    "# test_model_input['zip'] = 0\n",
    "print(test_model_input['zip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['zip'] = [0] * len(data)\n",
    "data['zip'] = [0 for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data.csv\")\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
